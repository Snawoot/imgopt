#!/usr/bin/env python

import sys
import ConfigParser
import os
import os.path
import threading
import subprocess
import logging
import hashlib
import json
import cPickle

GLOBAL = "global"
app_root = os.path.dirname(os.path.realpath(__file__))

WNULL = open(os.devnull, 'w')
RNULL = open(os.devnull, 'r')

cfg_defaults = {
    "jpegoptim"     :   "/usr/bin/jpegoptim",
    "optipng"       :   "/usr/bin/optipng",
    "optipng_opts"  :   "-o5 -preserve",
    "jpegoptim_opts":   "",
    "log"           :   "stderr",
    "threads"       :   8,
    "hashdb"        :   os.path.join(app_root, "imgopt.db"),
    "buffsize"      :   8 * 2**20,
}

class HashDB(object):
    def __init__(self, dbfile):
        self._dbfile = dbfile
        if os.path.isfile(dbfile):
            with open(dbfile, "rb") as f:
                self._hashes = cPickle.load(f)
        else:
            self._hashes = dict()

    def dump(self):
        tmpfile = self._dbfile + ".tmp"
        with open(tmpfile, "wb") as f:
            cPickle.dump(a, f, cPickle.HIGHEST_PROTOCOL)
        os.rename(tmpfile, self._dbfile)

    def __setitem__(self, key, value):
        self._hashes[key] = value

    def __delitem__(self, key, value):
        del self._hashes[key]

    def __getitem__(self, key):
        return self._hashes[key]

    def __len__(self):
        return len(self._hashes)

    def __contains__(self, key):
        return key in self._hashes

def prepare_logfile(logname):
    if logname == "stdout":
        return sys.stdout
    elif logname == "stderr":
        return sys.stderr
    else:
        return open(logname, "a")

def setup_logger(logfile, name, level=logging.INFO):
    logger = logging.getLogger(name)
    logger.setLevel(level)
    log_handler = logging.StreamHandler(logfile)
    log_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(log_handler)
    return logger

class ImageHandler(object):
    supported_extensions = []

    def __init__(self, binary_path, options):
        self._callargs = [ binary_path ]
        self._callargs.extend(options)

    def handle(self, path):
        args = list(self._callargs)
        args.append(path)
        s = subprocess.Popen(args, stdin=RNULL, stdout=WNULL, stderr=subprocess.STDOUT)
        s.wait()
        return s.returncode == 0

class JpegoptimHandler(ImageHandler):
    supported_extensions = ("jpg", "jpeg", "jpe", "jfif", "jif")

class OptipngHandler(ImageHandler):
    supported_extensions = ("png",)

class OptimizerRouter(object):
    def __init__(self):
        self._routes = dict()

    def add_handler(self, handler):
        for ext in handler.supported_extensions:
            self._routes[ext] = handler

    def _extract_type(self, path):
        return os.path.splitext(path)[1][1:].lower()

    def handle(self, path):
        ext = self._extract_type(path)
        if ext in self._routes:
            return self._routes[ext].handle(path)
        else:
            return False

    def known(self, path):
        return self._extract_type(path) in self._routes

class ImageOptimizer(object):
    def __init__(self, threads, router, hashdb, logger=None, buffsize=4096):
        if logger is None:
            self._logger = setup_logger(sys.stderr, "ImageOptimizer", logging.INFO)
        else:
            self._logger = logger
        self._threads = threads
        self._thread_sem = threading.BoundedSemaphore(self._threads)
        self._buffsize = buffsize
        self._hashdb = hashdb
        self._router = router

    def hash_file(self, filename):
        with open(filename, "rb") as f:
            H = hashlib.sha1()
            while True:
                data = f.read(self._buffsize)
                if not data:
                    break
                H.update(data)
        self._logger.debug("SHA1(%s) = %s", repr(filename), H.hexdigest())
        return H.digest()

    def __process_image_threaded(self, img_file, callback):
        try:
            h = self.hash_file(img_file)
            if h in self._hashdb:
                oldsize = self._hashdb[h]
                newsize = os.stat(img_file).st_size 
            else:
                oldsize = os.stat(img_file).st_size 
                if self._router.handle(img_file):
                    newsize = os.stat(img_file).st_size 
                    h = self.hash_file(img_file)
                    self._hashdb[h] = oldsize
                else:
                    self._logger.warn("Unable to process file \"%s\"", img_file)
                    newsize = oldsize
            callback(oldsize, newsize)
        except Exception as e:
            self._logger.error(e)
        finally:
            self._thread_sem.release()

    def __process_image(self, img_file, callback):
        self._thread_sem.acquire()
        t = threading.Thread(target = self.__process_image_threaded, args = (img_file, callback))
        t.start()

    def optimize_dir(self, path):
        results = {
            "oldsize": 0,
            "newsize": 0,
            "count":   0,
        }
        reslock = threading.Lock()
        self._logger.info("Processing directory \"%s\"...", path)
        def cb(before, after):
            with reslock:
                results["oldsize"] += before
                results["newsize"] += after
                results["count"] += 1
        for dp, dn, fn in os.walk(path):
            for filename in fn:
                if self._router.known(filename):
                    self.__process_image(os.path.join(dp, filename), cb)
        for i in xrange(self._threads):
            self._thread_sem.acquire()
        for i in xrange(self._threads):
            self._thread_sem.release()
        return results["oldsize"], results["newsize"], results["count"]

def main():
    cfgpath = os.path.join(app_root, "imgopt.ini")

    config = ConfigParser.RawConfigParser(cfg_defaults)
    configs = config.read(cfgpath)
    assert configs, "No config files read"
    sections = [ s for s in config.sections() if s != GLOBAL ]

    log = setup_logger(prepare_logfile(config.get(GLOBAL, "log")), "imgopt", logging.INFO)

    log.info("Reading hash DB...")
    hashdb = HashDB(config.get(GLOBAL, "hashdb"))

    log.info("Constructing objects...")
    
    optimizer_router = OptimizerRouter()
    optimizer_router.add_handler(
        JpegoptimHandler(
            config.get(GLOBAL, "jpegoptim"),
            config.get(GLOBAL, "jpegoptim_opts").split()
        )
    )
    optimizer_router.add_handler(
        OptipngHandler(
            config.get(GLOBAL, "optipng"),
            config.get(GLOBAL, "optipng_opts").split()
        )
    )
    optimizer = ImageOptimizer(config.getint(GLOBAL, "threads"), optimizer_router, hashdb, log, config.getint(GLOBAL, "buffsize"))

    log.info("Starting.")
    report = dict()
    for sect in sections:
        try:
            path = config.get(sect, "path")
        except ConfigParser.NoOptionError:
            log.warn("Config section \"%s\" has no \"path\" value specified! Skipping...", sect)
            continue

        if not os.path.isdir(path):
            log.warn("Config section \"%s\": \"path\" value %s doesn`t points to a directory! Skipping...", sect, repr(path))
            continue
        oldsize, newsize, count = optimizer.optimize_dir(path)
        report[sect] = {
            "path": path,
            "count": count,
            "oldsize": oldsize,
            "newsize": newsize,
        }

    log.info("Finished.")
    log.info("Saving hash DB...")
    hashdb.dump()
    json.dump(report, sys.stdout)

if __name__ == '__main__':
    main()
